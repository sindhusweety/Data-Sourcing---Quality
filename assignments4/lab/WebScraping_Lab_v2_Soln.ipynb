{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Python Web Scraping\n",
    "In this lab, you are to continue to build on the Dr. Who popularity solution. \n",
    "Recall, our research question is `who are the five most popular actors to play\n",
    "the role of Dr. Who in the popular and long running BBC series Dr. Who?`\n",
    "\n",
    "What remains to be completed is to evaluate the popularity of each Dr. Who actor by\n",
    "using the page views of the actor’s Wikipedia page as a proxy for their popularity.\n",
    "\n",
    "**DO NOT** attempt this lab until \n",
    "you have thoroughly reviewed the *BeautifulSoup_Module_INTRO_Lab*.   \n",
    "\n",
    "##  Using the Names + BeautifulSoup to Get the Stats\n",
    "Using the exact same principles used to collect the list of Dr. Who actors,\n",
    "we now need to collect the 30-day page view stat for each actor.\n",
    "\n",
    "The logic/pseudocode for this activity is roughly as follows:\n",
    "\n",
    "1. Explore the HTML underlying an example Wikipedia stats page:\n",
    "https://en.wikipedia.org/w/index.php?title=Jodie_Whittaker&action=info\n",
    "Look (**hard**) for a pattern that will allow you to capture the Page views in the past 30 days.\n",
    "Turns out there is perfect pattern you should be able to exploit.\n",
    "2. For each actor, combine the actor name with the Wikipedia URL string as a parameter\n",
    " - Fetch the stats web page by GET(ting) the URL just constructed\n",
    " - Parse the returned HTML using Beautiful Soup\n",
    " - Find the stats using your previously observed exploitable pattern\n",
    " - remove any noise from the stats string number\n",
    " - convert stats string to integer via int()\n",
    " - track the actor’s stat using a list or dictionary\n",
    "3. Sort the actor stats in descending order\n",
    "4. print the top 5\n",
    "\n",
    "Have a beer – you deserve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"heading-toc\" id=\"toc-ruth-claytonfugitive-doctor-jo-martin\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-thirteenth-doctor-jodie-whittaker\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-twelfth-doctor-peter-capaldi\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-war-doctor-john-hurt\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-eleventh-doctor-matt-smith\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-tenth-doctor-david-tennant\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-ninth-doctor-christopher-eccleston\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-eighth-doctor-paul-mcgann\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-seventh-doctor-sylvester-mccoy\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-sixth-doctor-colin-baker\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-fifth-doctor-peter-davison\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-fourth-doctor-tom-baker\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-third-doctor-jon-pertwee\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-second-doctor-patrick-troughton\"></span>\n",
      "<span class=\"heading-toc\" id=\"toc-first-doctor-william-hartnell\"></span>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=David_Tennant\" rel=\"nofollow\">246,790</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Sylvester_McCoy\" rel=\"nofollow\">35,143</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Colin_Baker\" rel=\"nofollow\">30,009</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Peter_Davison\" rel=\"nofollow\">75,132</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Jon_Pertwee\" rel=\"nofollow\">54,392</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Jodie_Whittaker\" rel=\"nofollow\">115,540</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Tom_Baker\" rel=\"nofollow\">93,924</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=William_Hartnell\" rel=\"nofollow\">46,945</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=John_Hurt\" rel=\"nofollow\">99,143</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Jo_Martin\" rel=\"nofollow\">9,769</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Peter_Capaldi\" rel=\"nofollow\">67,275</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Paul_McGann\" rel=\"nofollow\">58,283</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Patrick_Troughton\" rel=\"nofollow\">45,707</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Matt_Smith\" rel=\"nofollow\">132,795</a></div>\n",
      "<div class=\"mw-pvi-month\"><a class=\"external text\" href=\"https://pageviews.wmcloud.org/?project=en.wikipedia.org&amp;platform=all-access&amp;agent=user&amp;redirects=0&amp;range=latest-30&amp;pages=Christopher_Eccleston\" rel=\"nofollow\">76,660</a></div>\n",
      "['david tennant', 'matt smith', 'jodie whittaker', 'john hurt', 'tom baker', 'christopher eccleston', 'peter davison', 'peter capaldi', 'paul mcgann', 'jon pertwee', 'william hartnell', 'patrick troughton', 'sylvester mccoy', 'colin baker', 'jo martin']\n",
      "Drum roll please...\n",
      "The top 5 most popular Dr. Who actors are:\n",
      "\tdavid tennant : 246,790\n",
      "\tmatt smith : 132,795\n",
      "\tjodie whittaker : 115,540\n",
      "\tjohn hurt : 99,143\n",
      "\ttom baker : 93,924\n"
     ]
    }
   ],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import typing\n",
    "\n",
    "EW_URL = 'http://ew.com/tv/doctor-who-actors/'\n",
    "\n",
    "def simple_get(url, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url, *args, **kwargs)\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        resp.raise_for_status()\n",
    "\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "        raise http_err\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "        raise err\n",
    "\n",
    "    return resp\n",
    "\n",
    "# If you are having a hard time reading machine generate HTML you can\n",
    "# \"prettify\" the soup and print or save to a file.\n",
    "#  The prettify method prettifies the HTML with proper indents etc. making it much easier to read.\n",
    "# Arguments:\n",
    "# soup - BeautifulSoup object.  object representing HTML previously parsed by Beautiful Soup\n",
    "# o_file - output file handle. Expects a file name which will be opened for write ('w')\n",
    "#\n",
    "def prettify_html(soup: BeautifulSoup, o_file: str) -> None:\n",
    "    with open(o_file, mode='w', encoding='utf-8') as ofh:\n",
    "        prettyHTML = soup.prettify()  \n",
    "        print(prettyHTML, file=ofh, end=None)\n",
    "\n",
    "def make_soup(url: str) -> BeautifulSoup:\n",
    "    resp = simple_get(url, timeout=5)\n",
    "    html = resp.text\n",
    "\n",
    "    # sanity check. is this HTML?\n",
    "    assert re.search('html', resp.headers['Content-Type'], re.IGNORECASE)\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def who_actors(soup: BeautifulSoup) -> set:\n",
    "\n",
    "    # data to be returned\n",
    "    # Using a set here to ensure no duplicate names are returned.\n",
    "    # Need a quick refresher on Python sets?  See https://www.w3schools.com/python/python_sets.asp\n",
    "    actor_set = set()\n",
    "\n",
    "    # The following find_all finds the pattern in the span tag attributes that are used\n",
    "    # to isolate the Dr. Who actor names. When an attribute name like \"class\" collides with a Python\n",
    "    # reserved word (like \"class\") the BS module will always postfix an underscore character to that attribute.\n",
    "    # Hence, the \"class_\" attribute name below.\n",
    "    # BS allows you specify a compiled RE patter to match tags and/or attributes. Needless to say, this feature is very useful!\n",
    "    #\n",
    "    for span in soup.find_all('span', class_='heading-toc', id=re.compile(r'^toc-[\\w\\-]+\\-doctor\\-(.*)$')):\n",
    "\n",
    "        # I want the name from the id attribute which looks like this:\n",
    "        # id=\"toc-thirteenth-doctor-jodie-whittaker\"\n",
    "        # Another good use for REs.\n",
    "        print(span)\n",
    "        #\n",
    "        id = span['id']\n",
    "\n",
    "        m = re.search(r'^toc-[\\w\\-]+\\-doctor\\-(.*)$', id)\n",
    "        # if no match, then I've screwed up something\n",
    "        assert m is not None\n",
    "        actor = m.group(1).replace('-', ' ')\n",
    "        actor_set.add(actor)\n",
    "\n",
    "    # Great, got my list of actors. Return to caller\n",
    "    return actor_set\n",
    "\n",
    "'''\n",
    "    # PHASE 2:\n",
    "    # Collect the stats from Wikipedia\n",
    "    # for each who actor\n",
    "'''\n",
    "\n",
    "def who_stats(dr_who):\n",
    "    url = 'https://en.wikipedia.org/w/index.php'\n",
    "\n",
    "    # Notice that navigation to the info page is a query param\n",
    "    resp = simple_get(url, params=dict(title=dr_who, action ='info'))\n",
    "    # --OR--\n",
    "    #resp = simple_get(url, params={'title':dr_who, 'action': 'info'})\n",
    "\n",
    "\n",
    "    # get the decoded payload.  the text() method uses metadata to devine encoding.\n",
    "    html = resp.text\n",
    "\n",
    "    # By inspection of HTTP results you will find that the\n",
    "    # stat we seek is extremely easy to find:\n",
    "    # <div class=\"mw-pvi-month\">58,243</div>\n",
    "    # the <div> tag has a class attr designed to display the \"pvi\" - page view in...months!\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    #  Only need a find (not find_all) since there is only a single tag\n",
    "    # that has a class attr = mw-pvi-month\n",
    "\n",
    "    div = soup.find('div', class_='mw-pvi-month')\n",
    "    print(div)\n",
    "    # sanity check\n",
    "    assert div is not None\n",
    "    \n",
    "    # this text may have commas which need to be removed\n",
    "    # prior to parsing as an int\n",
    "    return int(div.text.replace(',',''))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    EW_URL = 'http://ew.com/tv/doctor-who-actors/'\n",
    "\n",
    "    # PHASE 1\n",
    "    # Get the Dr.Who actors from EW_URL\n",
    "    soup = make_soup(EW_URL)\n",
    "    #print(soup)\n",
    "\n",
    "    # If you want to examine a more readable version of the HTML\n",
    "    # use my prettify_html() function\n",
    "    prettify_html(soup, 'pretty_dr_who.html')\n",
    "\n",
    "    actor_set = who_actors(soup)\n",
    "\n",
    "    # PHASE 2:\n",
    "    # Collect the stats from Wikipedia for each who actor\n",
    "    #\n",
    "    actor_stats_dict = {}\n",
    "\n",
    "    # Iterate over the actor set.  For each actor, find their Wiki stats\n",
    "    # by constructing a name that is compatible with the URL requirements of Wikipedia.\n",
    "\n",
    "    for a in actor_set:\n",
    "        # the names from the EW are separated by \\s chars.  In wikipedia urls,\n",
    "        # those spaces need to become underscores (_) and the names are capitalized\n",
    "\n",
    "        # Special case McCoy!  Yikes!\n",
    "        first, last = a.split()\n",
    "        first = first[0].upper() + first[1:]\n",
    "\n",
    "        # If in the future, other such names occur, add the name prefixes to\n",
    "        # to the RE group(1) using alternation (|) operator.  Ex: (mc|von)\n",
    "        m = re.search(r'^(mc)(.*)$', last)\n",
    "        if(m):\n",
    "            last = m.group(1).title() + m.group(2).title()\n",
    "        else:\n",
    "            last = last[0].upper() + last[1:]\n",
    "\n",
    "        wiki_a = f'{first}_{last}'\n",
    "        pvim_stat = who_stats(wiki_a)\n",
    "        actor_stats_dict[a] = pvim_stat\n",
    "\n",
    "    # PHASE 3:\n",
    "    # Sort number of views in desc order\n",
    "    sorted_actor_list = sorted(actor_stats_dict, key=actor_stats_dict.get, reverse=True)\n",
    "    print(sorted_actor_list)\n",
    "    \n",
    "    print(\"Drum roll please...\\nThe top 5 most popular Dr. Who actors are:\")\n",
    "    for a in sorted_actor_list[0:5]:\n",
    "        cnt = actor_stats_dict[a]\n",
    "        # print numbers with thousands commas format\n",
    "        print(f'\\t{a} : {cnt:,}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0400823d55d45e049b5650d9f722273c95dfd46d59c82a1ad996971de83cf4d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
